#!/usr/bin/env -S poetry run python

from functools import partial
from multiprocessing import Pool
from os import cpu_count
from pathlib import Path
from typing import List, Tuple

import click
import numpy as np
from PIL import ImageFile
from sklearn.model_selection import train_test_split
from torch.functional import Tensor
from torchvision.datasets.folder import default_loader
from torchvision.transforms.functional import (
    InterpolationMode,
    center_crop,
    gaussian_blur,
    resize,
    to_tensor,
)
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True


def process(source: Path, lr_size: int, hr_size: int) -> Tuple[np.array, np.array]:
    image: Tensor = to_tensor(default_loader(source))

    hr = center_crop(image, hr_size)

    # Sigma taken from “Perceptual Losses for Real-Time Style Transfer and Super-Resolution”.
    lr = gaussian_blur(hr, kernel_size=9, sigma=1.0)
    lr = resize(lr, lr_size, interpolation=InterpolationMode.BICUBIC)

    lr = lr.numpy()
    hr = hr.numpy()

    return lr, hr


def convert(
    files: List[Path],
    target: Path,
    lr_size: int,
    scale_factor: int,
    channels: int,
    jobs: int,
):
    hr_size = lr_size * scale_factor

    lr_batch = np.empty((len(files), channels, lr_size, lr_size), dtype=np.float32)
    hr_batch = np.empty((len(files), channels, hr_size, hr_size), dtype=np.float32)

    with Pool(jobs) as pool, tqdm(files, unit="file") as files_:
        process_ = partial(process, lr_size=lr_size, hr_size=hr_size)

        for index, (lr_sample, hr_sample) in enumerate(
            pool.imap_unordered(process_, files_)
        ):
            lr_batch[index] = lr_sample
            hr_batch[index] = hr_sample

    np.save(target.with_suffix(".lr.npy"), lr_batch)
    np.save(target.with_suffix(".hr.npy"), hr_batch)


def prepare(root: Path, lr_size: int, scale_factor: int, jobs: int):
    root.mkdir(exist_ok=True, parents=True)

    files = []
    files += root.rglob("*.png")
    files += root.rglob("*.jpg")

    train, test = train_test_split(files, test_size=0.2)

    convert(test, root / "test", lr_size, scale_factor, 3, jobs)
    convert(train, root / "train", lr_size, scale_factor, 3, jobs)


@click.command()
@click.option("--root", required=True, type=Path)
@click.option("--lr-size", required=True, type=int)
@click.option("--scale-factor", required=True, type=int)
@click.option("--jobs", required=True, type=int, default=cpu_count())
def cli(root: Path, lr_size: int, scale_factor: int, jobs: int):
    return prepare(root, lr_size, scale_factor, jobs)


if __name__ == "__main__":
    cli()
