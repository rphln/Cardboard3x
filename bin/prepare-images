#!/usr/bin/env -S poetry run python

from functools import partial
from multiprocessing import Pool
from os import cpu_count
from pathlib import Path
from typing import List, Optional, Tuple

import click
import numpy as np
from numpy.lib.format import open_memmap
from PIL import ImageFile
from sklearn.model_selection import train_test_split
from torch.functional import Tensor
from torchvision.datasets.folder import default_loader
from torchvision.transforms.functional import (
    InterpolationMode,
    center_crop,
    gaussian_blur,
    resize,
    to_tensor,
)
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True


def process(source: Path, lr_size: int, hr_size: int) -> Tuple[np.array, np.array]:
    image: Tensor = to_tensor(default_loader(source))

    hr = center_crop(image, hr_size)

    # Sigma taken from “Perceptual Losses for Real-Time Style Transfer and Super-Resolution”.
    lr = gaussian_blur(hr, kernel_size=9, sigma=1.0)
    lr = resize(lr, lr_size, interpolation=InterpolationMode.BICUBIC)

    lr = lr.numpy()
    hr = hr.numpy()

    return lr, hr


def convert(
    files: List[Path],
    target: Path,
    lr_size: int,
    scale_factor: int,
    channels: int,
    jobs: int,
):
    hr_size = lr_size * scale_factor

    lr = target.with_suffix(".lr.npy")
    hr = target.with_suffix(".hr.npy")

    lr = open_memmap(lr, "w+", np.float32, (len(files), channels, lr_size, lr_size))
    hr = open_memmap(hr, "w+", np.float32, (len(files), channels, hr_size, hr_size))

    with Pool(jobs) as pool, tqdm(files, unit="file") as files_:
        process_ = partial(process, lr_size=lr_size, hr_size=hr_size)

        for index, (lr_sample, hr_sample) in enumerate(
            pool.imap_unordered(process_, files_)
        ):
            lr[index] = lr_sample
            hr[index] = hr_sample


@click.command()
@click.option("--source", required=True, type=Path)
@click.option("--target", required=True, type=Path)
@click.option("--lr-size", required=True, type=int)
@click.option("--scale-factor", required=True, type=int)
@click.option("--jobs", required=True, type=int, default=cpu_count())
@click.option("--test-ratio", required=False, type=float, default=None)
def cli(
    source: Path,
    target: Path,
    lr_size: int,
    scale_factor: int,
    jobs: int,
    test_ratio: Optional[float],
):
    target.mkdir(exist_ok=True, parents=True)

    files = []
    files += source.rglob("*.png")
    files += source.rglob("*.jpg")

    if test_ratio:
        train, test = train_test_split(files, test_size=test_ratio)
        convert(test, target / "test", lr_size, scale_factor, 3, jobs)
    else:
        train = files

    convert(train, target / "train", lr_size, scale_factor, 3, jobs)


if __name__ == "__main__":
    cli()
