{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38734bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet h5py kornia pytorch-lightning scikit-learn torch torchvision wandb\n",
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5c4b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from os import PathLike\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import h5py\n",
    "import torch\n",
    "from kornia.losses import psnr as psnr_score\n",
    "from kornia.losses import ssim as ssim_score\n",
    "from pytorch_lightning import LightningDataModule, LightningModule, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import Tensor\n",
    "from torch.nn import Conv2d, Module, MSELoss, PixelShuffle, Sequential, Tanh\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.transforms.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272372b5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "except ImportError:\n",
    "    pass\n",
    "else:\n",
    "    drive.mount(\"/content/drive/\", force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49017326",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ln -s /content/drive/MyDrive/ var/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb216b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp var/rphln-danbooru2020-small.{train,test}.h5 /dev/shm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93dc9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ESPCN(Sequential):\n",
    "    SCALE = 4\n",
    "    N0 = 3\n",
    "\n",
    "    F1 = 5\n",
    "    N1 = 64\n",
    "\n",
    "    F2 = 3\n",
    "    N2 = 32\n",
    "\n",
    "    F3 = 3\n",
    "    N3 = N0 * (SCALE ** 2)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = Sequential(\n",
    "            Conv2d(self.N0, self.N1, self.F1, padding=\"same\"),\n",
    "            Tanh(),\n",
    "            Conv2d(self.N1, self.N2, self.F2, padding=\"same\"),\n",
    "            Tanh(),\n",
    "        )\n",
    "        self.head = Sequential(\n",
    "            Conv2d(self.N2, self.N3, self.F3, padding=\"same\"),\n",
    "            PixelShuffle(4),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec35d16",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mean_psnr(u: Tensor, v: Tensor) -> Tensor:\n",
    "    return psnr_score(u, v, 1).mean()\n",
    "\n",
    "\n",
    "def mean_ssim(u: Tensor, v: Tensor) -> Tensor:\n",
    "    return ssim_score(u, v, 9).mean()\n",
    "\n",
    "\n",
    "class LitModel(LightningModule):\n",
    "    def __init__(self, model: Module, criterion: Module, learning_rate: float = 0.001):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = normalize(x, std=[0.2931, 0.2985, 0.2946], mean=[0.7026, 0.6407, 0.6265])\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, index):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "\n",
    "        loss = self.criterion(z, y)\n",
    "        self.log(\"Training/Loss\", loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, index):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "\n",
    "        loss = self.criterion(z, y)\n",
    "        self.log(\"Validation/Loss\", loss)\n",
    "\n",
    "        psnr = mean_psnr(z, y)\n",
    "        self.log(\"Validation/PSNR\", psnr)\n",
    "\n",
    "        ssim = mean_ssim(z, y)\n",
    "        self.log(\"Validation/SSIM\", ssim)\n",
    "\n",
    "    def test_step(self, batch, index):\n",
    "        x, y = batch\n",
    "        z = self(x)\n",
    "\n",
    "        psnr = mean_psnr(z, y)\n",
    "        self.log(\"Testing/PSNR\", psnr)\n",
    "\n",
    "        ssim = mean_ssim(z, y)\n",
    "        self.log(\"Testing/SSIM\", ssim)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        parameters = [\n",
    "            {\"params\": self.model.stem.parameters(), \"lr\": self.learning_rate},\n",
    "            {\"params\": self.model.head.parameters(), \"lr\": self.learning_rate * 0.1},\n",
    "        ]\n",
    "\n",
    "        return Adam(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97aaa395",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class TensorPairsDataset(Dataset[Tuple[Tensor, Tensor]]):\n",
    "    def __init__(self, name):\n",
    "        with h5py.File(name, \"r\") as h5:\n",
    "            self.lr = torch.as_tensor(h5[\"lr\"][:])\n",
    "            self.hr = torch.as_tensor(h5[\"hr\"][:])\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        lr = self.lr[index]\n",
    "        hr = self.hr[index]\n",
    "\n",
    "        return lr, hr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr)\n",
    "\n",
    "\n",
    "class TensorPairsDataModule(LightningDataModule):\n",
    "    batch_size: int\n",
    "\n",
    "    train_with: Union[Path, PathLike, str]\n",
    "    test_with: Union[Path, PathLike, str]\n",
    "\n",
    "    training: TensorPairsDataset\n",
    "    validation: TensorPairsDataset\n",
    "    testing: TensorPairsDataset\n",
    "\n",
    "    test_ratio: float = 0.2\n",
    "\n",
    "    drop_last: bool = True\n",
    "    pin_memory: bool = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_with: Union[Path, PathLike, str],\n",
    "        test_with: Union[Path, PathLike, str],\n",
    "        batch_size: int,\n",
    "        test_ratio: float = test_ratio,\n",
    "        drop_last: bool = drop_last,\n",
    "        pin_memory: bool = pin_memory,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_with = train_with\n",
    "        self.test_with = test_with\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.drop_last = drop_last\n",
    "        self.pin_memory = pin_memory\n",
    "\n",
    "        self.test_ratio = test_ratio\n",
    "\n",
    "    def setup(self, stage: Optional[str] = None):\n",
    "        if stage in (None, \"fit\"):\n",
    "            self.training, self.validation = train_test_split(\n",
    "                TensorPairsDataset(self.train_with),\n",
    "                test_size=self.test_ratio,\n",
    "                shuffle=False,\n",
    "            )\n",
    "\n",
    "        if stage in (None, \"test\"):\n",
    "            self.testing = TensorPairsDataset(self.test_with)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.training,\n",
    "            self.batch_size,\n",
    "            drop_last=self.drop_last,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.validation,\n",
    "            self.batch_size,\n",
    "            drop_last=self.drop_last,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.testing,\n",
    "            self.batch_size,\n",
    "            drop_last=self.drop_last,\n",
    "            pin_memory=self.pin_memory,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709635df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "config = {\n",
    "    \"BATCH_SIZE\": 1024,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "}\n",
    "\n",
    "model = LitModel(\n",
    "    model=ESPCN(),\n",
    "    criterion=MSELoss(),\n",
    "    learning_rate=config[\"LEARNING_RATE\"],\n",
    ")\n",
    "data = TensorPairsDataModule(\n",
    "    batch_size=config[\"BATCH_SIZE\"],\n",
    "    test_with=\"/dev/shm/rphln-danbooru2020-small.test.h5\",\n",
    "    train_with=\"/dev/shm/rphln-danbooru2020-small.train.h5\",\n",
    ")\n",
    "\n",
    "wandb = WandbLogger(project=\"Cardboard4\", config=config, save_dir=\"var\")\n",
    "wandb.watch(model)\n",
    "\n",
    "trainer = Trainer(\n",
    "    gpus=1,\n",
    "    precision=16,\n",
    "    logger=wandb,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(monitor=\"Validation/Loss\", dirpath=wandb.save_dir),\n",
    "        EarlyStopping(monitor=\"Validation/Loss\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "trainer.fit(model, datamodule=data)\n",
    "trainer.test(datamodule=data)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}