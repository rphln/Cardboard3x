{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe958c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'git+https://github.com/rphln/Cardboard4.git@code'\n",
    "\n",
    "from os import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c6eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from ignite.contrib.handlers import ProgressBar, WandBLogger\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.handlers import (\n",
    "    Checkpoint,\n",
    "    DiskSaver,\n",
    "    EarlyStopping,\n",
    "    global_step_from_engine,\n",
    ")\n",
    "from ignite.metrics import Loss, RunningAverage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.nn import Conv2d, MSELoss, PixelShuffle, Sequential, Tanh\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "from cardboard4 import TensorPairsDataset, mean_psnr, mean_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive/\", force_remount=True)\n",
    "except ImportError:\n",
    "    ROOT = Path(\"var/\")\n",
    "else:\n",
    "    ROOT = Path(\"/content/drive/MyDrive/\")\n",
    "finally:\n",
    "    ROOT.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3a118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsync --archive --ignore-existing --human-readable --info progress2 '/content/drive/MyDrive/rphln-danbooru2020-small' 'var/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc82e802",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r '/content/drive/MyDrive/.netrc' '/root/.netrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESPCN(Sequential):\n",
    "    SCALE = 4\n",
    "    N0 = 3\n",
    "\n",
    "    F1 = 5\n",
    "    N1 = 64\n",
    "\n",
    "    F2 = 3\n",
    "    N2 = 32\n",
    "\n",
    "    F3 = 3\n",
    "    N3 = N0 * (SCALE ** 2)\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.normalize = Normalize(\n",
    "            std=[0.2931, 0.2985, 0.2946], mean=[0.7026, 0.6407, 0.6265]\n",
    "        )\n",
    "\n",
    "        self.stem = Sequential(\n",
    "            Conv2d(self.N0, self.N1, self.F1, padding=\"same\"),\n",
    "            Tanh(),\n",
    "            Conv2d(self.N1, self.N2, self.F2, padding=\"same\"),\n",
    "            Tanh(),\n",
    "        )\n",
    "        self.head = Sequential(\n",
    "            Conv2d(self.N2, self.N3, self.F3, padding=\"same\"),\n",
    "            PixelShuffle(4),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14fb614",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 2048,\n",
    "    \"LEARNING_RATE\": 0.001,\n",
    "    \"PATIENCE\": 100,\n",
    "}\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "test_with = TensorPairsDataset(Path(\"var\") / \"rphln-danbooru2020-small\" / \"test\")\n",
    "train_with = TensorPairsDataset(Path(\"var\") / \"rphln-danbooru2020-small\" / \"train\")\n",
    "\n",
    "train_with, validate_with = train_test_split(train_with, test_size=0.2, shuffle=False)\n",
    "\n",
    "training_data_loader = DataLoader(\n",
    "    train_with,\n",
    "    config[\"BATCH_SIZE\"],\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=cpu_count(),\n",
    "    persistent_workers=True,\n",
    ")\n",
    "validation_data_loader = DataLoader(\n",
    "    validate_with,\n",
    "    config[\"BATCH_SIZE\"],\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=cpu_count(),\n",
    "    persistent_workers=True,\n",
    ")\n",
    "testing_data_loader = DataLoader(\n",
    "    test_with,\n",
    "    config[\"BATCH_SIZE\"],\n",
    "    drop_last=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=cpu_count(),\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "criterion = MSELoss()\n",
    "\n",
    "model = ESPCN()\n",
    "model.to(device)\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": model.stem.parameters(), \"lr\": config[\"LEARNING_RATE\"]},\n",
    "    {\"params\": model.head.parameters(), \"lr\": config[\"LEARNING_RATE\"] * 0.1},\n",
    "]\n",
    "\n",
    "optimizer = Adam(parameters)\n",
    "\n",
    "metrics = {\n",
    "    \"loss\": Loss(criterion),\n",
    "    \"psnr\": Loss(mean_psnr),\n",
    "    \"ssim\": Loss(mean_ssim),\n",
    "}\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
    "\n",
    "validation = create_supervised_evaluator(model, metrics, device)\n",
    "testing = create_supervised_evaluator(model, metrics, device)\n",
    "\n",
    "average = RunningAverage(output_transform=lambda loss: loss)\n",
    "average.attach(trainer, \"loss\")\n",
    "\n",
    "ProgressBar(persist=True).attach(trainer, metric_names=\"all\")\n",
    "ProgressBar(persist=True).attach(validation, metric_names=\"all\")\n",
    "ProgressBar(persist=True).attach(testing, metric_names=\"all\")\n",
    "\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def compute_metrics():\n",
    "    validation.run(validation_data_loader)\n",
    "\n",
    "\n",
    "@trainer.on(Events.COMPLETED)\n",
    "def compute_testing_metrics():\n",
    "    testing.run(testing_data_loader)\n",
    "\n",
    "\n",
    "logger = WandBLogger(\n",
    "    project=\"Cardboard4\",\n",
    "    config=config,\n",
    "    save_code=True,\n",
    "    dir=ROOT / \"wandb\",\n",
    ")\n",
    "logger.watch(model, criterion, log=\"all\")\n",
    "\n",
    "logger.attach_output_handler(\n",
    "    engine=trainer,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"training\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "logger.attach_output_handler(\n",
    "    engine=validation,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"validation\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "logger.attach_output_handler(\n",
    "    engine=testing,\n",
    "    event_name=Events.EPOCH_COMPLETED,\n",
    "    tag=\"testing\",\n",
    "    metric_names=\"all\",\n",
    "    global_step_transform=global_step_from_engine(trainer),\n",
    ")\n",
    "\n",
    "neg_loss_score = Checkpoint.get_default_score_fn(\"loss\", -1.0)\n",
    "\n",
    "halt = EarlyStopping(\n",
    "    trainer=trainer,\n",
    "    patience=config[\"PATIENCE\"],\n",
    "    score_function=neg_loss_score,\n",
    ")\n",
    "validation.add_event_handler(Events.COMPLETED, halt)\n",
    "\n",
    "validation.add_event_handler(\n",
    "    Events.COMPLETED,\n",
    "    Checkpoint(\n",
    "        n_saved=1,\n",
    "        to_save={\n",
    "            \"halt\": halt,\n",
    "            \"model\": model,\n",
    "            \"optimizer\": optimizer,\n",
    "            \"trainer\": trainer,\n",
    "            \"validator\": validation,\n",
    "        },\n",
    "        include_self=True,\n",
    "        save_handler=DiskSaver(dirname=logger.run.dir, require_empty=False),\n",
    "        score_name=\"loss\",\n",
    "        score_function=neg_loss_score,\n",
    "        global_step_transform=global_step_from_engine(trainer),\n",
    "    ),\n",
    ")\n",
    "\n",
    "trainer.run(training_data_loader, 3_000)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
