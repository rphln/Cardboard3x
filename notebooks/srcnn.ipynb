{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edd2775b",
   "metadata": {},
   "source": [
    "# SRCNN\n",
    "\n",
    "O modelo descrito é o \"Super-Resolution Convolutional Neural Network\", ou SRCNN, criado por Chao Dong *et al.* em 2015.\n",
    "\n",
    "A rede é composta por três camadas convolucionais, intercaladas pela função de ativação ReLU. As imagens passam por uma interpolação bicúbica antes de serem alimentadas à rede.\n",
    "\n",
    "Aqui, usamos a configuração 9-5-5 para tamanho de filtros. A primeira camada produz 64 canais, enquanto a segunda camada produz 32 canais.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e96bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import Conv2d, Module, init\n",
    "from torch.nn.functional import interpolate, mse_loss, relu\n",
    "\n",
    "from srnn import Model\n",
    "\n",
    "\n",
    "def conv2d(in_channels, out_channels, kernel_size) -> Module:\n",
    "    return Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "\n",
    "\n",
    "class SRCNN(Model):\n",
    "    N0 = 1\n",
    "    N1 = 64\n",
    "    N2 = 32\n",
    "\n",
    "    F1 = 9\n",
    "    F2 = 5\n",
    "    F3 = 5\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv2d(\n",
    "            in_channels=self.N0, out_channels=self.N1, kernel_size=self.F1\n",
    "        )\n",
    "        self.conv2 = conv2d(\n",
    "            in_channels=self.N1, out_channels=self.N2, kernel_size=self.F2\n",
    "        )\n",
    "        self.conv3 = conv2d(\n",
    "            in_channels=self.N2, out_channels=self.N0, kernel_size=self.F3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = interpolate(x, scale_factor=3, mode=\"bicubic\", align_corners=False)\n",
    "        x = relu(self.conv1(x), inplace=True)\n",
    "        x = relu(self.conv2(x), inplace=True)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return f\"{self.__class__.__name__}_unclamped\"\n",
    "\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, Conv2d):\n",
    "        init.normal_(module.weight, std=1e-3)\n",
    "        init.constant_(module.bias, val=0e-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b53ea8a",
   "metadata": {},
   "source": [
    "## Dependências comuns\n",
    "\n",
    "Definimos aqui as dependências comuns a todos os modelos treinados e o conjunto de treinamento; também exibimos uma pequena parcela, selecionada aleatoriamente, do conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "386cfd93",
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = '/tmp/testing.h5', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5e55544295ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagePairsDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensorPairsDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorPairsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/testing.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImagePairsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/testing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/University/Trabalho de Conclusão de Curso/GitHub/src/srnn/tensor_pairs_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTensorPairsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"latest\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/srnn-ftEomi4i-py3.8/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, **kwds)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nslots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_nbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrdcc_w0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0m\u001b[1;32m    443\u001b[0m                                fapl, fcpl=make_fcpl(track_order=track_order, fs_strategy=fs_strategy,\n\u001b[1;32m    444\u001b[0m                                fs_persist=fs_persist, fs_threshold=fs_threshold),\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/srnn-ftEomi4i-py3.8/lib/python3.8/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = '/tmp/testing.h5', errno = 2, error message = 'No such file or directory', flags = 40, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from srnn import Model, training\n",
    "from srnn.dataset import ImagePairsDataset, TensorPairsDataset\n",
    "\n",
    "dataset = TensorPairsDataset(\"/tmp/testing.h5\")\n",
    "dataset = ImagePairsDataset(Path(\"/tmp/testing\").glob(\"*\"), lr_size=32, scale=3)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "lr, hr = next(iter(loader))\n",
    "\n",
    "display(to_pil_image(make_grid(hr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1f56c2",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Por fim, realizamos o treinamento da rede. O artigo especifica a taxa de aprendizado das duas primeiras camadas como 10<sup>-4</sup> e da última camada como 10<sup>-5</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117508b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = SRCNN()\n",
    "model.apply(init_weights)\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": model.conv1.parameters()},\n",
    "    {\"params\": model.conv2.parameters()},\n",
    "    {\"params\": model.conv3.parameters(), \"lr\": LEARNING_RATE * 0.1},\n",
    "]\n",
    "\n",
    "training(\n",
    "    model,\n",
    "    parameters,\n",
    "    mse_loss,\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    save_interval=10,\n",
    "    device=\"cuda:0\",\n",
    "    dataset=dataset,\n",
    "    checkpoints=Path(\"var/checkpoints\"),\n",
    "    name=\"{model}-{fold}.pth\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "44c148707aa4f9d1f7f69aa4d16b47b58de939bb852ab93b81a55772f9b10087"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}