{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65937d7a",
   "metadata": {},
   "source": [
    "# SRCNN\n",
    "\n",
    "O modelo descrito é o \"Super-Resolution Convolutional Neural Network\", ou SRCNN, criado por Chao Dong *et al.* em 2015.\n",
    "\n",
    "A rede é composta por três camadas convolucionais, intercaladas pela função de ativação ReLU. As imagens passam por uma interpolação bicúbica antes de serem alimentadas à rede.\n",
    "\n",
    "Aqui, usamos a configuração 9-5-5 para tamanho de filtros. A primeira camada produz 64 canais, enquanto a segunda camada produz 32 canais.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d322820",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.nn import Conv2d, Module, init\n",
    "from torch.nn.functional import interpolate, mse_loss, relu\n",
    "\n",
    "from srnn import Model\n",
    "\n",
    "\n",
    "def conv2d(in_channels, out_channels, kernel_size) -> Module:\n",
    "    return Conv2d(in_channels, out_channels, kernel_size, padding=kernel_size // 2)\n",
    "\n",
    "\n",
    "class SRCNN(Model):\n",
    "    N0 = 3\n",
    "    N1 = 64\n",
    "    N2 = 32\n",
    "\n",
    "    F1 = 9\n",
    "    F2 = 5\n",
    "    F3 = 5\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = conv2d(\n",
    "            in_channels=self.N0, out_channels=self.N1, kernel_size=self.F1\n",
    "        )\n",
    "        self.conv2 = conv2d(\n",
    "            in_channels=self.N1, out_channels=self.N2, kernel_size=self.F2\n",
    "        )\n",
    "        self.conv3 = conv2d(\n",
    "            in_channels=self.N2, out_channels=self.N0, kernel_size=self.F3\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = interpolate(x, scale_factor=3, mode=\"bicubic\", align_corners=False)\n",
    "        x = relu(self.conv1(x), inplace=True)\n",
    "        x = relu(self.conv2(x), inplace=True)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return f\"{self.__class__.__name__}_unclamped\"\n",
    "\n",
    "\n",
    "def init_weights(module):\n",
    "    if isinstance(module, Conv2d):\n",
    "        init.normal_(module.weight, std=1e-3)\n",
    "        init.constant_(module.bias, val=0e-0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031ec32b",
   "metadata": {},
   "source": [
    "## Dependências comuns\n",
    "\n",
    "Definimos aqui as dependências comuns a todos os modelos treinados e o conjunto de treinamento; também exibimos uma pequena parcela, selecionada aleatoriamente, do conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f84a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import display\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from srnn import Model, training\n",
    "from srnn.dataset import ImagePairsDataset, TensorPairsDataset\n",
    "\n",
    "dataset = ImagePairsDataset(\n",
    "    \"/media/rphln/Taihou/Datasets/rphln-safebooru2020-small-cropped/training\"\n",
    ")\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "lr, hr = next(iter(loader))\n",
    "\n",
    "display(to_pil_image(make_grid(hr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ff430e",
   "metadata": {},
   "source": [
    "## Treinamento\n",
    "\n",
    "Por fim, realizamos o treinamento da rede. O artigo especifica a taxa de aprendizado das duas primeiras camadas como 10<sup>-4</sup> e da última camada como 10<sup>-5</sup>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec71175",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "model = SRCNN()\n",
    "model.apply(init_weights)\n",
    "\n",
    "parameters = [\n",
    "    {\"params\": model.conv1.parameters()},\n",
    "    {\"params\": model.conv2.parameters()},\n",
    "    {\"params\": model.conv3.parameters(), \"lr\": LEARNING_RATE * 0.1},\n",
    "]\n",
    "\n",
    "training(\n",
    "    model,\n",
    "    parameters,\n",
    "    mse_loss,\n",
    "    epochs=30,\n",
    "    batch_size=256,\n",
    "    save_interval=10,\n",
    "    device=\"cuda:0\",\n",
    "    dataset=dataset,\n",
    "    checkpoints=Path(\"var/checkpoints\"),\n",
    "    name=\"{model}-{fold}.pth\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "encoding": "# -*- coding: utf-8 -*-",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
